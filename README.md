<h1>Benchmarking Active Learning Virtual Screening across Vina, Glide, and SILCS-based docking at a Transmembrane Binding Site</h1>

<h2>Project Abstract</h2>
The rapid expansion of large chemical libraries has led to the need for efficient and accurate virtual screening pipelines. Active learning workflows, such as MolPAL and Active Learning Glide, have emerged as scalable solutions that iteratively train surrogate models to prioritize promising compounds, thereby reducing the number of required docking calculations. However, direct benchmarking of active learning protocols across different docking engines and their performance on membrane-embedded binding sites remains unclear. Here, we present a benchmark comparison of four active learning virtual screening protocols: Vina-MolPAL, Glide-MolPAL, SILCS-MolPAL, and Schrödinger’s active learning Glide. Active learning performance was evaluated in terms of recovery of the top molecules, predictive accuracy, chemical diversity, and computational cost. Vina-MolPAL achieved the highest top-1% recovery. SILCS-MolPAL, which incorporates SILCS-Monte Carlo docking scores, reached comparable accuracy and recovery at larger batch sizes while providing a more realistic description of heterogeneous membrane environments. These results demonstrate that the choice of the docking algorithm has a substantial impact on active learning performance. Importantly, combining SILCS-MC with the active learning strategy enables rigorous yet computationally feasible virtual screening of large databases targeting transmembrane binding sites.


<h2>Dataset files</h2>
We had three docking datasets, each dataset corresponding to a different docking model: SILCS-MC, Glide, and Autodock-Vina. The datasets were provided in the CSV format, featuring a column containing the SMILES string and the respective docking score. The CSV files were separated into the 40k set used for active learning and the 5k test. 
